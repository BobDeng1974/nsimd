<!--

Copyright (c) 2019 Agenium Scale

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

-->

<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>NSIMD documentation</title>
    <style type="text/css">
      body {
        /*margin:40px auto;*/
        margin:10px auto;
        /*max-width:650px;*/
        max-width:800px;
        /*line-height:1.6;*/
        line-height:1.4;
        /*font-size:18px;*/
        color:#444;
        padding:0 10px
      }
      h1,h2,h3 {
        line-height:1.2
      }
      table,th, td {
        border: 1px solid gray;
        border-collapse : collapse;
        padding: 1px 3px;
      }
    </style>
    <!-- https://www.mathjax.org/#gettingstarted -->
    <script src="assets/polyfill.min.js"></script>
    <script id="MathJax-script" async src="assets/tex-mml-chtml.js"></script>
    <!-- Highlight.js -->
    <link rel="stylesheet" href= "assets/highlight.js.default.min.css">
    <script src="assets/highlight.min.js"></script>
    <script src="assets/cpp.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
  </head>
<body>

<center>
  <img src="img/logo.svg"><br>
  <br>
  <a href="index.html">Index</a> |
  <a href="quick_start.html">Quick Start</a> |
  <a href="tutorials.html">Tutorials</a> |
  <a href="faq.html">FAQ</a> |
  <a href="contribute.html">Contribute</a> |
  <a href="overview.html">API overview</a> |
  <a href="api.html">API reference</a>
</center>
<h1>Introduction</h1>
<p>Single instruction, multiple data (<a href="https://en.wikipedia.org/wiki/SIMD">SIMD</a>)
instructions or multimedia extensions have been available for many years.
They are designed to significantly accelerate code execution, however they
require expertise to be used correctly, depends on non-uniform compiler support,
the use of low-level intrinsics, or vendor-specific libraries.</p>
<p><a href="https://github.com/agenium-scale/nsimd"><code>nsimd</code></a> is library which aims to
simplify the error-prone process of developing application exploiting the
potential of SIMD instructions sets. <code>nsimd</code> is designed to seamlessly integrate
into existing projects so that you can quickly and easily start developing high
performance, portable and future proof software.</p>
<h2>Why use <code>nsimd</code>?</h2>
<p><code>nsimd</code> standardizes and simplifies the use of SIMD instructions across hardware
by not relying on verbose, low-level SIMD instructions. Furthermore, the
portability of <code>nsimd</code> eliminates the need to re-write cumbersome code for each
revision of each target architecture, accounting for each architecture&apos;s vendor
provided API as well as architecture dependent implementation details. This
greatly reduces the design complexity and maintenance of SIMD code,
significantly decreasing the time required to develop, test and deploy software
as well as decreasing the scope for introducing bugs.</p>
<p><code>nsimd</code> allows you to focus on the important part of your work: the development
of new features and functionality. We take care of all of the architecture and
compiler specific details and we provide updates when new architectures are
released by manufacturers. All you have to do is re-compile your code every time
you target a new architecture.</p>
<h2>Inside <code>nsimd</code></h2>
<p><code>nsimd</code> is a vectorization library that abstracts SIMD programming. It was
designed to exploit the maximum power of processors at a low development cost.</p>
<p>To achieve maximum performance, <code>nsimd</code> mainly relies on the inline optimization
pass of the compiler. Therefore using any mainstream compiler such as GCC,
Clang, MSVC, XL C/C++, ICC and others with <code>nsimd</code> will give you a zero-cost
SIMD abstraction library.</p>
<p>To allow inlining, a lot of code is placed in header files. <em>Small</em> functions
such as addition, multiplication, square root, etc, are all present in header
files whereas big functions such as I/O are put in source files that are
compiled as a <code>.so</code>/<code>.dll</code> library.</p>
<p><code>nsimd</code> provides C89, C++98, C++11 and C++14 APIs. All APIs allow writing
generic code. For the C API this is achieved through a thin layer of macros; for
the C++ APIs it is achieved using templates and function overloading. The C++
API is split in two. The first part is a C-like API with only function calls and
direct type definitions for SIMD types while the second one provides operator
overloading, higher level type definitions that allows unrolling. C++11, C++14
APIs add for instance templated type definitions and templated constants.</p>
<p>Binary compatibility is guaranteed by the fact that only a C ABI is exposed. The
C++ API only wraps the C calls.</p>
<h2><code>nsimd</code> Philosophy</h2>
<p>The library aims to provide a portable zero-cost abstraction over SIMD vendor
intrinsics disregarding the underlying SIMD vector length.</p>
<p>NSIMD was designed following as closely as possible the following guidelines:</p>
<ul>
<li><p>Do not aim for a fully <a href="https://en.wikipedia.org/wiki/IEEE_754">IEEE</a>
compliant library, rely on intrinsics, errors induced by non compliance are
small and acceptable.</p></li>
<li><p>Correctness primes over speed.</p></li>
<li><p>Emulate with tricks and intrinsic integer arithmetic when not available.</p></li>
<li><p>Use common names as found in common computation libraries.</p></li>
<li><p>Do not hide SIMD registers, one variable (of a type such as <code>nsimd::pack</code>)
matches one register.</p></li>
<li><p>Keep the code simple to allow the compiler to perform as many optimizations as
possible.</p></li>
</ul>
<p>You may wrap intrinsics that require compile time knowledge of the underlying
vector length but this should be done with caution.</p>
<p>Wrapping intrinsics that do not exist for all types is difficult and may require
casting or emulation. For instance, 8 bit integer vector multiplication using
<code>SSE2</code> does not exist. We can either process each pair of integers individually or
we can cast the 8 bit vectors to 16 bit vectors, do the multiplication and cast
them back to 8 bit vectors. In the second case, chaining operations will
generate many unwanted casts.</p>
<p>To avoid hiding important details to the user, overloads of operators involving
scalars and SIMD vectors are not provided by default. Those can be included
explicitely to emphasize the fact that using expressions like <code>scalar + vector</code>
might incur an optimization penalty.</p>
<p>The use of <code>nsimd::pack</code> may not be portable to ARM <code>SVE</code> and therefore must be
included manually. ARM <code>SVE</code> registers can only be stored in sizeless structs
(<code>__sizeless_struct</code>). This feature (as of 2019/04/05) is only supported by the
ARM compiler. We do not know whether other compilers will use the same keyword
or paradigm to support SVE intrinsics.</p>
<h2>A Short Example Using <code>nsimd</code></h2>
<p>Let&apos;s take a simple case where we calculate the sum of two vectors of 32-bit
floats:</p>
<pre class="C++"><code>for (size_t i = 0; i &lt; N; ++i) {
  out[i] = in0[i] + in1[i];
}</code></pre>

<p>Each element of the results vector is independent of every other element -
therefore this function may easily be vectorized as there is latent data
parallelism which may be exploited. This simple loop may be vectorized for an
x86 processor using Intel intrinsic functions. For example, the following code
vectorizes this loop for a SSE enabled processor:</p>
<pre class="C++"><code>size_t len_sse = 4;
for (size_t i = 0; i &lt; N; i += len_sse) {
  __m128 v0_sse = _mm_load_ps(&amp;in0[i]);
  __m128 v1_sse = _mm_load_ps(&amp;in1[i]);
  __m128 r_sse = _mm_add_ps(v0_sse, v1_sse);
  _mm_store_ps(&amp;out[i], r_sse);
}</code></pre>

<p>Looks difficult? How about we vectorize it for the following generation of Intel
processor equipped with AVX instructions:</p>
<pre class="C++"><code>std::size_t len_avx = 8;
for (size_t i = 0; i &lt; N; i += len_avx) {
  __m256 v0_avx = _mm256_load_ps(&amp;in0[i]);
  __m256 v1_avx = _mm256_load_ps(&amp;in1[i]);
  __m256 r_avx = _mm256_add_ps(v0_avx, v1_avx);
  _mm256_store_ps(&amp;out[i], r_avx);
}</code></pre>

<p>Both of these processors are manufactured by Intel yet two different versions of
the code are required to get the best performance possible from each processor.
This is quickly getting complicated and annoying.</p>
<p>Now, look at how the code can become simpler with <code>nsimd</code>.</p>
<p><code>nsimd</code> C++11 version without the advanced API:</p>
<pre class="C++"><code>size_t len = size_t(nsimd::len(f32()));
for (size_t i = 0; i &lt; N; i += len) {
  // auto is nsimd::simd_vector&lt;f32&gt;
  auto v0 = nsimd::loada(&amp;in0[i], f32());
  auto v1 = nsimd::loada(&amp;in1[i], f32());
  auto r = nsimd::add(v0, v1, f32());
  nsimd::storea(&amp;out[i], r, f32());
}</code></pre>

<p><code>nsimd</code> C++11 version using the advanced API (not recommended for portability
with ARM <code>SVE</code>):</p>
<pre class="C++"><code>size_t len = size_t(nsimd::len(f32()));
for (size_t i = 0; i &lt; N; i += len) {
  // auto is nsimd::pack&lt;f32&gt;
  auto v0 = nsimd::loada&lt;nsimd::pack&lt;f32&gt; &gt;(&amp;in0[i]);
  auto v1 = nsimd::loada&lt;nsimd::pack&lt;f32&gt; &gt;(&amp;in1[i]);
  auto r = v0 + v1;
  nsimd::storea(&amp;out[i], r);
}</code></pre>

<p><code>nsimd</code> C++98 version without the advanced API:</p>
<pre class="C++"><code>size_t len = size_t(nsimd::len(f32()));
typedef nsimd::simd_traits&lt;f32, nsimd::NSIMD_SIMD&gt;::simd_vector vec_t;
for (size_t i = 0; i &lt; N; i += len) {
  vec_t v0 = nsimd::loada(&amp;in0[i], f32());
  vec_t v1 = nsimd::loada(&amp;in1[i], f32());
  vec_t r = nsimd::add(v0, v1, f32());
  nsimd::storea(&amp;out[i], r, f32());
}</code></pre>

<p><code>nsimd</code> C++98 version using the advanced API (not recommended for portability
with ARM <code>SVE</code>):</p>
<pre class="C++"><code>size_t len = size_t(nsimd::len(f32()));
for (size_t i = 0; i &lt; N; i += len) {
  nsimd::pack&lt;f32&gt; v0 = nsimd::loada&lt;nsimd::pack&lt;f32&gt; &gt;(&amp;in0[i]);
  nsimd::pack&lt;f32&gt; v1 = nsimd::loada&lt;nsimd::pack&lt;f32&gt; &gt;(&amp;in1[i]);
  nsimd::pack&lt;f32&gt; r = v0 + v1;
  nsimd::storea(&amp;out[i], r);
}</code></pre>

<p><code>nsimd</code> C (C89, C99, C11) version:</p>
<pre class="C"><code>size_t len = (size_t)vlen(f32);
size_t i;
for (i = 0; i &lt; N; i += len) {
  vec(f32) v0 = vloada(&amp;in0[i], f32);
  vec(f32) v1 = vloada(&amp;in1[i], f32);
  vec(f32) r = vadd(v0, v1, f32);
  vstorea(&amp;out[i], r, f32);
}</code></pre>

<p>Download full source code:</p>
<ul>
<li><p><a href="../src/hello_world.cpp">hello_world.cpp</a></p></li>
<li><p><a href="../src/hello_world.c">hello_world.c</a></p></li>
</ul>
<h2>Supported Compilers and Hardware by <code>nsimd</code></h2>
<p><code>nsimd</code> includes support for some Intel and ARM processors. The support of
IBM processors is ongoing and will be available soon.</p>
<table>
<thead>
<tr>
<td style="text-align: left;"><b>Architecture</b></td>
<td style="text-align: left;"><b>Extensions</b></td>
</tr>
</thead><tbody>
<tr>
<td style="text-align: left;">Intel</td>
<td style="text-align: left;"><code>SSE2</code>, <code>SSE4.2</code>, <code>AVX</code>, <code>AVX2</code>, <code>AVX-512</code> (<code>KNL</code> and <code>SKYLAKE</code>)</td>
</tr>
<tr>
<td style="text-align: left;">ARM</td>
<td style="text-align: left;"><code>Aarch64</code>, <code>NEON</code> (<code>ARMv7</code>), <code>SVE</code></td>
</tr>
</tbody>
</table>
<p><code>nsimd</code> is tested with GCC, Clang and MSVC. As a C89 and a C++98 API are
provided, other compilers should work fine. Old compiler versions should work as
long as they support the targeted SIMD extension. For instance, <code>nsimd</code> can
compile on MSVC 2010 <code>SSE4.2</code> code.</p>
<p><code>nsimd</code> requires a C or a C++ compiler and is actually daily tested on the
following compilers for the following hardware:</p>
<table>
<thead>
<tr>
<td style="text-align: left;"><b>Compiler</b></td>
<td style="text-align: left;"><b>Version</b></td>
<td style="text-align: left;"><b>Architecture</b></td>
<td style="text-align: left;"><b>Extensions</b></td>
</tr>
</thead><tbody>
<tr>
<td style="text-align: left;">GCC</td>
<td style="text-align: left;">8.3.0</td>
<td style="text-align: left;">Intel</td>
<td style="text-align: left;"><code>SSE2</code>, <code>SSE4.2</code>, <code>AVX</code>, <code>AVX2</code>, <code>AVX-512</code> (<code>KNL</code> and <code>SKYLAKE</code>)</td>
</tr>
<tr>
<td style="text-align: left;">Clang</td>
<td style="text-align: left;">7.0.1</td>
<td style="text-align: left;">Intel</td>
<td style="text-align: left;"><code>SSE2</code>, <code>SSE4.2</code>, <code>AVX</code>, <code>AVX2</code>, <code>AVX-512</code> (<code>KNL</code> and <code>SKYLAKE</code>)</td>
</tr>
<tr>
<td style="text-align: left;">GCC</td>
<td style="text-align: left;">8.3.0</td>
<td style="text-align: left;">ARM</td>
<td style="text-align: left;"><code>Aarch64</code>, <code>NEON</code> (<code>ARMv7</code>), <code>SVE</code></td>
</tr>
<tr>
<td style="text-align: left;">Clang</td>
<td style="text-align: left;">7.0.1</td>
<td style="text-align: left;">ARM</td>
<td style="text-align: left;"><code>Aarch64</code>, <code>NEON</code> (<code>ARMv7</code>), <code>SVE</code></td>
</tr>
<tr>
<td style="text-align: left;">Microsoft Visual Studio</td>
<td style="text-align: left;">2017</td>
<td style="text-align: left;">Intel</td>
<td style="text-align: left;"><code>SSE4.2</code></td>
</tr>
<tr>
<td style="text-align: left;">Intel C++ Compiler</td>
<td style="text-align: left;">19.0.4.243</td>
<td style="text-align: left;">Intel</td>
<td style="text-align: left;"><code>SSE2</code>, <code>SSE4.2</code>, <code>AVX</code>, <code>AVX2</code>, <code>AVX-512</code> (<code>SKYLAKE</code>)</td>
</tr>
</tbody>
</table>

<h2>Contributing</h2>
<p>The wrapping of intrinsics, the writing of test and bench files are tedious and
repetitive tasks. Most of those are generated using Python scripts that can be
found in <code>egg</code>.</p>
<ul>
<li><p>Intrinsics that do not require to known the vector length can be wrapped and
will be accepted with no problem.</p></li>
<li><p>Intrinsics that do require the vector length at compile time can be wrapped
but it is up to the maintainer to accept it.</p></li>
<li><p>Use <code>clang-format</code> when writing C or C++ code.</p></li>
<li><p>The <code>.cpp</code> files are written in C++14.</p></li>
<li><p>The headers files must be compatible with C89 (when possible otherwise
C99), C++98, C++11 and C++14.</p></li>
</ul>
<p>Please see <a href="contribute.html">contribute</a> for more details.</p>
  </body>
</html>
